{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../CodeSearchNet/big_csn_data/CodeSearchNet_Java_Search_Preliminary.pkl\"\n",
    "infile = open(filename,'rb')\n",
    "new_dict = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1 #+(100000)*15\n",
    "print(new_dict[i]['function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(new_dict[i]['function_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonDataLineByLine(JsonFile):\n",
    "    data = []\n",
    "    i = 0\n",
    "    with open(JsonFile) as f:\n",
    "        for line in f:\n",
    "            i += 1\n",
    "            line = line.strip()\n",
    "            if line[0] == '[':\n",
    "                line = line[1:]\n",
    "            elif line[-1] == ']':\n",
    "                line = line[:-1]\n",
    "            if line[-1] == ',':\n",
    "                line = line[:-1]\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "                if i%10000 == 0: print(i, \"success\")\n",
    "            except:\n",
    "                data.append('''{\"classBodyDeclaration\": \"\"}''')\n",
    "                print(i, \"failure\")\n",
    "                print(line)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travarse(tree):\n",
    "    if 'type' in tree:\n",
    "        print(tree['text'], end=\" \")\n",
    "        if tree['text'] in [';', '{', '}']:\n",
    "            print()\n",
    "        return\n",
    "    else:\n",
    "        root = list(tree.keys())[0]\n",
    "        children = tree[root]\n",
    "        for child in children:\n",
    "            travarse(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(tree2code(tree_data[i],0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printCode(tree):\n",
    "    code, _ = tree2code(tree, 0)\n",
    "    print(code)\n",
    "    print(\"Count:\", len(code.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls ../csn_big_only_trees/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompressed_data = getJsonData('../csn_big_only_trees/csn_big_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_data = getJsonData('../CodeSearchNet/train_test_valid_data_10k/java_train_1u_10k_compressed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_comp = 0\n",
    "aft_comp = 0\n",
    "for i in range(len(compressed_data)):\n",
    "    code, _ = tree2code(uncompressed_data[i], 0)\n",
    "    num_tokens = len(code.split())\n",
    "    compressed_tokens = len(compressed_data[i]['code'].split())\n",
    "    bef_comp += num_tokens\n",
    "    aft_comp += compressed_tokens\n",
    "    if not compressed_tokens:\n",
    "        aft_comp += num_tokens\n",
    "\n",
    "print(1-aft_comp/bef_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "code, _ = tree2code(uncompressed_data[i], 0)\n",
    "num_tokens = len(code.split())\n",
    "print(code)\n",
    "print(num_tokens)\n",
    "print(\"================================\")\n",
    "print(compressed_data[i]['code'])\n",
    "compressed_tokens = len(compressed_data[i]['code'].split())\n",
    "print(compressed_tokens)\n",
    "print(\"Compression Ratio:\", compressed_tokens/num_tokens)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2104572106016639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many of the compressed tokens were present in the top 10k train data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_dict = getJsonData('../CodeSearchNet/abstract_code_dict_500k_w_child.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_keys = sorted(abstract_code_dict, key = lambda x:abstract_code_dict[x]['count'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_dict[abstract_code_keys[110]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_25k = [abstract_code_dict[abstract_code_keys[i]]['compressed_name'] for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_10k = [abstract_code_dict[abstract_code_keys[i]]['compressed_name'] for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_freq_25k[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir ../CodeSearchNet/25k\n",
    "#!mv ../CodeSearchNet/train-test-valid_25kf.zip ../CodeSearchNet/25k/\n",
    "#!unzip ../CodeSearchNet/25k/train-test-valid_25kf.zip\n",
    "!ls ../CodeSearchNet/train_test_valid_data_10k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "dirs = glob.glob('../CodeSearchNet/train_test_valid_data_10k_500k/*_train_*')\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = {}\n",
    "for path in dirs:\n",
    "    dataset = getJsonData(path)\n",
    "    for data in dataset:\n",
    "        code = data['code']\n",
    "        code_tokens = code.split()\n",
    "        for token in code_tokens:\n",
    "            if token not in freq_dict:\n",
    "                freq_dict[token] = 0\n",
    "            freq_dict[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25k compressed total tokens: 1024352\n",
    "# 10k compressed total tokens: 1160247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_freq_list = sorted(freq_dict, key = lambda x:freq_dict[x], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_data_freq_list = data_freq_list[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_data_freq_list[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_tokens = list(set(top_data_freq_list) & set(most_freq_10k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(common_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_data_freq_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumping common union vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_10k_10k = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in top_data_freq_list:\n",
    "    list_10k_10k.append({'token':token, 'count':freq_dict[token]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_compressed_tokens = list(set(most_freq_10k) - set(top_data_freq_list))\n",
    "len(additional_compressed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in additional_compressed_tokens:\n",
    "    if token in freq_dict:\n",
    "        list_10k_10k.append({'token':token, 'count':freq_dict[token]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_10k_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(list_10k_10k, \"list_10k_10k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out data outside vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_vocab = list(set(most_freq_10k) - set(top_data_freq_list))\n",
    "len(not_in_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_in_vocab[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in not_in_vocab:\n",
    "    print(f,\"||\", func2abs[f],\"||\", abstract_code_dict[func2abs[f]]['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in common_tokens[:1000]:\n",
    "    print(f,\"||\", func2abs[f],\"||\", abstract_code_dict[func2abs[f]]['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abstract_code_dict[abstract_code_keys[10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abstract_code_dict['( ( AbstractISUPParameter ) $id0 ) . decode ( $id1 ) ;']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'$F2570015' in common_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(abstract_code_keys)\n",
    "#1144264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "abstract_code_keys2 = []\n",
    "for key in abstract_code_keys:\n",
    "    i+=1\n",
    "    parent = key + \" ;\" \n",
    "    if parent in abstract_code_keys:\n",
    "        if not i%1000: print(i)\n",
    "        if abstract_code_dict[key]['count'] != abstract_code_dict[parent]['count']:\n",
    "            abstract_code_keys2.append(key)\n",
    "\n",
    "abstract_code_keys = abstract_code_keys2\n",
    "len(abstract_code_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "abstract_code_keys2 = []\n",
    "for key in abstract_code_keys:\n",
    "    i+=1\n",
    "    if not i%100: print(i)\n",
    "    #abstract_code_keys.remove(key)\n",
    "    abstract_code_keys2.append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing child counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = freq_dict[data_freq_list[30000]]\n",
    "min_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for discard_after in range(len(abstract_code_keys)):\n",
    "    key = abstract_code_keys[discard_after]\n",
    "    if abstract_code_dict[key]['count'] <= min_freq:\n",
    "        break\n",
    "discard_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func2abs = {}\n",
    "\n",
    "for key in abstract_code_dict:\n",
    "    func2abs[abstract_code_dict[key]['compressed_name']] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_abstract_keys = abstract_code_keys[:discard_after]\n",
    "abstract_code_dict_modified = copy.deepcopy(abstract_code_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in accepted_abstract_keys:\n",
    "    children = abstract_code_dict[key]['children']\n",
    "    if children:\n",
    "        count = abstract_code_dict[key]['count']\n",
    "        for child in children:\n",
    "            try:\n",
    "                child_key = func2abs[child]\n",
    "            except:\n",
    "                print(\"parent:\", abstract_code_dict_modified[key], \"child:\", child)\n",
    "            abstract_code_dict_modified[child_key]['count'] -= count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_keys = sorted(abstract_code_dict_modified, key = lambda x:abstract_code_dict_modified[x]['count'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for discard_after in range(len(abstract_code_keys)):\n",
    "    key = abstract_code_keys[discard_after]\n",
    "    if abstract_code_dict_modified[key]['count'] <= min_freq:\n",
    "        break\n",
    "discard_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_abstract_keys = abstract_code_keys[:discard_after]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_data_freq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_dict2 = getJsonData('../CodeSearchNet/abstract_code_dict_500k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_abstract_funcs = [ abstract_code_dict2[x]['compressed_name'] for x in accepted_abstract_keys ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_vocab = list(set(accepted_abstract_funcs) & set(top_data_freq_list))\n",
    "len(not_in_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "    \n",
    "def dump_dict(data, name):\n",
    "    with open(name, 'w', encoding=\"utf8\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def tree2code(tree, indentation):\n",
    "    code = \"\"\n",
    "    parent = list(tree.keys())[0]\n",
    "    children = tree[parent]\n",
    "    if 'type' in tree:\n",
    "        code = tree['text'] + ' '\n",
    "        if tree['text'] in [';', '{', '}']:\n",
    "            code += '\\n'\n",
    "            if tree['text'] == '{':\n",
    "                indentation += 1\n",
    "            elif tree['text'] == '}':\n",
    "                indentation -= 1\n",
    "            code += '\\t'*indentation\n",
    "        #return code, indentation\n",
    "    elif len(children)==1 and parent == \"literal\":\n",
    "        child = children[0]\n",
    "        child_text = child[\"text\"]\n",
    "        #type(ast.literal_eval(child_text))\n",
    "        try:\n",
    "            if child_text in ['null', 'true', 'false']:\n",
    "                code = child_text + \" \"\n",
    "            elif type(ast.literal_eval(child_text)) == type(\"STRING\"):\n",
    "                code = \"STRING00 \"\n",
    "            elif type(ast.literal_eval(child_text)) == type(1):\n",
    "                code = \"INT00 \"\n",
    "            elif type(ast.literal_eval(child_text)) == type(1.1):\n",
    "                code = \"FLOAT00 \"\n",
    "        except:\n",
    "            code = \"NUM00 \"\n",
    "    else:\n",
    "        root = list(tree.keys())[0]\n",
    "        children = tree[root]\n",
    "        for child in children:\n",
    "            t, indentation = tree2code(child, indentation)\n",
    "            code += t\n",
    "    return code, indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def get_compressed_func():\n",
    "    global compression_number\n",
    "    compression_number += 1\n",
    "    return \"$F\"+str(compression_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict(tree):\n",
    "    var_list = []\n",
    "    global abstract_code_dict_copy\n",
    "    global abstract_code_keys\n",
    "    \n",
    "    \n",
    "    if 'text' in tree:\n",
    "        code = tree[\"text\"] + \" \"\n",
    "        #print(\"**:\\t\",code, 1)\n",
    "        return (code, 1, 0, [], None)\n",
    "    else:\n",
    "        parent = list(tree.keys())[0]\n",
    "        children = tree[parent]\n",
    "        if len(children) == 0:\n",
    "            return (\"\", 0, 0, [], None)\n",
    "        \n",
    "        code = \"\"\n",
    "        compressed_func = None\n",
    "        leaf_count = 0\n",
    "        id_count = 0\n",
    "        children_list = []\n",
    "        #leaf_list = []\n",
    "        \n",
    "        '''\n",
    "        and not (len(children) == 2 and 'text' in children[1] and children[1]['text'] == ';')\\\n",
    "        and not (len(children) == 3 and 'text' in children[0] and 'text' in children[2] and \\\n",
    "                 ((children[0]['text'] == '(' and children[2]['text'] == ')') or \n",
    "                  (children[0]['text'] == '{' and children[2]['text'] == '}') or\n",
    "                  (children[0]['text'] == '[' and children[2]['text'] == ']')))\n",
    "        '''\n",
    "        \n",
    "        if len(children) > 1:\n",
    "            for child in children:\n",
    "                (c, n, i, vl, f) = build_dict(child)\n",
    "                code += c\n",
    "                leaf_count += n\n",
    "                id_count += i\n",
    "                var_list += [v for v in vl if v not in var_list]\n",
    "                if f: children_list.append(f)\n",
    "                #else: leaf_list += code.split()\n",
    "                \n",
    "            if (var_list and leaf_count - len(var_list) >= 4) or (not var_list and leaf_count > 1) :\n",
    "                abstract_code = code.split()\n",
    "                for i in range(len(abstract_code)):\n",
    "                    if abstract_code[i] in var_list:\n",
    "                        abstract_code[i] = \"$id{}\".format(var_list.index(abstract_code[i]))\n",
    "                abstract_code = ' '.join(abstract_code)\n",
    "                \n",
    "                if abstract_code not in abstract_code_dict:\n",
    "                    compressed_func = get_compressed_func()\n",
    "                    abstract_code_dict[abstract_code] = {\n",
    "                        'count': 0, \n",
    "                        'compressed_name': compressed_func,\n",
    "                        'num_params': len(var_list),\n",
    "                        'children': children_list,\n",
    "                        #'leaves': leaf_list\n",
    "                    }\n",
    "                else:\n",
    "                    compressed_func = abstract_code_dict[abstract_code]['compressed_name']\n",
    "                \n",
    "                abstract_code_dict[abstract_code]['count'] += 1\n",
    "#                 children_list.insert(0, compressed_func)\n",
    "                \n",
    "            return (code, leaf_count, id_count, var_list, compressed_func)\n",
    "        \n",
    "        if parent == \"literal\":\n",
    "            child = children[0]\n",
    "            child_text = child[\"text\"]\n",
    "            try:\n",
    "                if child_text in ['null', 'true', 'false']:\n",
    "                    pass\n",
    "                elif type(ast.literal_eval(child_text)) == type(\"STRING\"):\n",
    "                    children[0][\"text\"] = \"STRING00\"\n",
    "                elif type(ast.literal_eval(child_text)) == type(1):\n",
    "                    children[0][\"text\"] = \"INT00\"\n",
    "                elif type(ast.literal_eval(child_text)) == type(1.1):\n",
    "                    children[0][\"text\"] = \"FLOAT00\"\n",
    "            except:\n",
    "                children[0][\"text\"] = \"NUM00\"\n",
    "            code = children[0][\"text\"] + \" \"\n",
    "#==================================================================\n",
    "        elif parent == \"primary\" and 'type' in children[0]:\n",
    "            id_count += 1\n",
    "            text = children[0][\"text\"]\n",
    "            if text not in var_list:\n",
    "                var_list.append(text)\n",
    "            code = text + \" \"\n",
    "        elif parent == \"variableDeclaratorId\" and 'type' in children[0]:\n",
    "            id_count += 1\n",
    "            text = children[0][\"text\"]\n",
    "            if text not in var_list:\n",
    "                var_list.append(text)\n",
    "            code = text + \" \"\n",
    "#=================================================================\n",
    "        else:\n",
    "            (code, leaf_count, i, vl, compressed_func) = build_dict(children[0])\n",
    "            id_count += i\n",
    "            var_list += [v for v in vl if v not in var_list]\n",
    "        \n",
    "        return (code, leaf_count, id_count, var_list, compressed_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(tree):\n",
    "    var_list = []\n",
    "    global abstract_code_dict_copy\n",
    "    global abstract_code_keys\n",
    "    \n",
    "    if 'text' in tree:\n",
    "        code = tree[\"text\"] + \" \"\n",
    "        #print(\"**:\\t\",code, 1)\n",
    "        return (code, 1, 0, [])\n",
    "    else:\n",
    "        parent = list(tree.keys())[0]\n",
    "        children = tree[parent]\n",
    "        if len(children) == 0:\n",
    "            return (\"\", 0, 0, [])\n",
    "        \n",
    "        code = \"\"\n",
    "        compressed_func = None\n",
    "        leaf_count = 0\n",
    "        id_count = 0\n",
    "        children_list = []\n",
    "        \n",
    "        if len(children) > 1:\n",
    "            for child in children:\n",
    "                (c, n, i, vl) = compress(child)\n",
    "                code += c\n",
    "                leaf_count += n\n",
    "                id_count += i\n",
    "                var_list += [v for v in vl if v not in var_list]\n",
    "                #if f: children_list.append(f)\n",
    "                #else: leaf_list += code.split()\n",
    "                \n",
    "            if (var_list and leaf_count - len(var_list) >= 4) or (not var_list and leaf_count > 1) :\n",
    "                abstract_code = code.split()\n",
    "                for i in range(len(abstract_code)):\n",
    "                    if abstract_code[i] in var_list:\n",
    "                        abstract_code[i] = \"$id{}\".format(var_list.index(abstract_code[i]))\n",
    "                abstract_code = ' '.join(abstract_code)\n",
    "                \n",
    "                #---------------------------------------------------\n",
    "                if abstract_code in abstract_code_keys:\n",
    "                    #print(\"compressing!!\")\n",
    "                    compressed_func = abstract_code_dict_copy[abstract_code]['compressed_name']\n",
    "                    compressed_func += ' ( ' +' , '.join(var_list)+' )' if var_list else ''\n",
    "                    tree[parent] = [{\"type\": \"compressed\", \"text\": compressed_func}]\n",
    "                #---------------------------------------------------\n",
    "\n",
    "            return (code, leaf_count, id_count, var_list)\n",
    "        \n",
    "        if parent == \"literal\":\n",
    "            child = children[0]\n",
    "            child_text = child[\"text\"]\n",
    "            try:\n",
    "                if child_text in ['null', 'true', 'false']:\n",
    "                    pass\n",
    "                elif type(ast.literal_eval(child_text)) == type(\"STRING\"):\n",
    "                    children[0][\"text\"] = \"STRING00\"\n",
    "                elif type(ast.literal_eval(child_text)) == type(1):\n",
    "                    children[0][\"text\"] = \"INT00\"\n",
    "                elif type(ast.literal_eval(child_text)) == type(1.1):\n",
    "                    children[0][\"text\"] = \"FLOAT00\"\n",
    "            except:\n",
    "                children[0][\"text\"] = \"NUM00\"\n",
    "            code = children[0][\"text\"] + \" \"\n",
    "            \n",
    "        elif parent == \"primary\" and 'type' in children[0]:\n",
    "            id_count += 1\n",
    "            text = children[0][\"text\"]\n",
    "            if text not in var_list:\n",
    "                var_list.append(text)\n",
    "            code = text + \" \"\n",
    "        elif parent == \"variableDeclaratorId\" and 'type' in children[0]:\n",
    "            id_count += 1\n",
    "            text = children[0][\"text\"]\n",
    "            if text not in var_list:\n",
    "                var_list.append(text)\n",
    "            code = text + \" \"\n",
    "        else:\n",
    "            (code, leaf_count, i, vl) = compress(children[0])\n",
    "            id_count += i\n",
    "            var_list += [v for v in vl if v not in var_list]\n",
    "        \n",
    "        return (code, leaf_count, id_count, var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading one training data\n",
    "tree_data = getJsonData(\"../test_data/java_train_3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Dictionary\n",
    "[Parent Child](#Parent-child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num items first: 411762\n",
    "# After removing children low frequency than 10,000th in freq_dict: 4810\n",
    "# After deducing parent frequency from children: 2922\n",
    "# After "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_dict = {}\n",
    "compression_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for data in tree_data:\n",
    "    if not i%5000: print(i)\n",
    "    build_dict(data)\n",
    "    i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dump_dict(abstract_code_dict, '../test_data/abstract_code_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 ]\n",
      "[ 5000 ]\n",
      "[ 10000 ]\n",
      "[ 15000 ]\n",
      "[ 20000 ]\n",
      "[ 25000 ]\n",
      "[ 29999 ]\n"
     ]
    }
   ],
   "source": [
    "## build freq_dict\n",
    "freq_dict_original = {}\n",
    "uncompressed_codes = []\n",
    "\n",
    "for i in range(len(tree_data)):\n",
    "    if i%5000 == 0: print(\"[\", i, \"]\")\n",
    "    code, _ = tree2code(tree_data[i], 0)\n",
    "    uncompressed_codes.append({\"code\": code})\n",
    "    tokens = code.split()\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in freq_dict_original: freq_dict_original[token] = 0\n",
    "        freq_dict_original[token] += 1\n",
    "print(\"[\", i, \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(freq_dict_original, '../test_data/freq_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(uncompressed_codes, \"../test_data/uncompressed_codes_no_literal_train_3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_dict = getJsonData('../test_data/abstract_code_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "func2abs = {}\n",
    "\n",
    "for key in abstract_code_dict:\n",
    "    func2abs[abstract_code_dict[key]['compressed_name']] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict_original = getJsonData('../test_data/freq_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Reruns, run from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411762"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "abstract_code_dict_copy = copy.deepcopy(abstract_code_dict)\n",
    "abstract_code_keys = sorted(abstract_code_dict_copy, key = lambda x:abstract_code_dict_copy[x]['count'], reverse=True)\n",
    "len(abstract_code_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82769"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = copy.deepcopy(freq_dict_original)\n",
    "most_freq = sorted(freq_dict, key = lambda x:freq_dict[x], reverse=True)\n",
    "len(most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ceMask_', 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = freq_dict[most_freq[vocab_size]]\n",
    "most_freq[vocab_size], min_freq\n",
    "# 10k : ('nColors', 11)\n",
    "# 30k: ('ceMask_', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21195"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens that are less than the min-count, will not appear on the final vocab\n",
    "\n",
    "for key in list(abstract_code_dict_copy):\n",
    "    if abstract_code_dict_copy[key]['count'] < min_freq:\n",
    "        del abstract_code_dict_copy[key]\n",
    "abstract_code_keys = sorted(abstract_code_dict_copy, key = lambda x:abstract_code_dict_copy[x]['count'], reverse=True)\n",
    "len(abstract_code_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the frequency of every parent from their children, because if parent exist in the vocabulary, child will not\n",
    "\n",
    "for key in abstract_code_keys:\n",
    "    children = abstract_code_dict_copy[key]['children']\n",
    "    count = abstract_code_dict_copy[key]['count']\n",
    "    for child in children:\n",
    "        child_key = func2abs[child]\n",
    "        if child_key in abstract_code_dict_copy:\n",
    "            abstract_code_dict_copy[child_key]['count'] -= count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### Removing again all tokens with less frequent than min-count\n",
    "\n",
    "for key in list(abstract_code_dict_copy):\n",
    "    if abstract_code_dict_copy[key]['count'] < min_freq:\n",
    "        del abstract_code_dict_copy[key]\n",
    "len(abstract_code_dict_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "abstract_code_keys = sorted(abstract_code_dict_copy, key = lambda x:abstract_code_dict_copy[x]['count'], reverse=True)\n",
    "len(abstract_code_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10k\n",
    "# Before operation total keys: 4810\n",
    "# After decreasing child count and removing lower than min_count: 2922\n",
    "# Functions survived after addidngg in freq_dict: 2001\n",
    "# Ended up after compression: 1989\n",
    "# Compressio Ratio: 0.8567161502728318\n",
    "\n",
    "### 30k\n",
    "# Before operation total keys: \n",
    "# After decreasing child count and removing lower than min_count: 2776\n",
    "# Functions survived after addidngg in freq_dict: 2770\n",
    "# Ended up after compression:\n",
    "# Compression Ratio: 0.8987381335587129\n",
    "\n",
    "### Compress child and token together: 10k\n",
    "# Coverage: 0.9927927927927928\n",
    "# Functions survived after addidngg in freq_dict: 2220\n",
    "# Ended up after compression: 2204\n",
    "# Compression Ration: 0.8523115931079496\n",
    "\n",
    "### Compress child and token together: 30k\n",
    "# Coverage: \n",
    "# Functions survived after addidngg in freq_dict: 6663\n",
    "# Ended up after compression: \n",
    "# Compression Ration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82769"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for key in abstract_code_keys:\n",
    "    func = abstract_code_dict_copy[key]['compressed_name']\n",
    "    freq_dict[func] = abstract_code_dict_copy[key]['count']\n",
    "len(freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = copy.deepcopy(freq_dict_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instead of reducing the compressed child frequency before, we do it with removing other tokens\n",
    "#### Recursion\n",
    "\n",
    "i = 0\n",
    "accepted_functions = []\n",
    "for key in abstract_code_keys:\n",
    "    if not i%500: print(i, \":\", len(accepted_functions))\n",
    "    i+=1\n",
    "    func = abstract_code_dict_copy[key]['compressed_name']\n",
    "    freq_dict[func] = abstract_code_dict_copy[key]['count']\n",
    "    most_freq = sorted(freq_dict, key = lambda x:freq_dict[x], reverse=True)\n",
    "    accepted_functions = list(set(func2abs) & set(most_freq[:vocab_size]))\n",
    "    \n",
    "    if func in most_freq[:vocab_size]:\n",
    "        count = abstract_code_dict_copy[key]['count']\n",
    "        children = abstract_code_dict_copy[key]['children']\n",
    "        accepted_functions.append(func)\n",
    "        tokens = key.split()\n",
    "        \n",
    "        # Should be recursive\n",
    "        nodes_to_visit = [func]\n",
    "        while nodes_to_visit:\n",
    "            currentnode = nodes_to_visit.pop(0)\n",
    "            children = abstract_code_dict_copy[func2abs[currentnode]]['children']\n",
    "            nodes_to_visit = children + nodes_to_visit\n",
    "            if children:\n",
    "                for child in children:\n",
    "                    if child in freq_dict:\n",
    "                        freq_dict[child] -= count\n",
    "                    else:\n",
    "                        print(child, \"is less frequent than parent\", func)\n",
    "            else:\n",
    "                for token in tokens:\n",
    "                    if not token.startswith(\"$id\") and token in freq_dict:\n",
    "                        freq_dict[token] -= count\n",
    "    \n",
    "\n",
    "most_freq = sorted(freq_dict, key = lambda x:freq_dict[x], reverse=True)\n",
    "accepted_functions = list(set(func2abs) & set(most_freq[:vocab_size]))\n",
    "print(i, \":\", len(accepted_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0\n",
      "$F356864 is less frequent than parent $F356865\n",
      "$F355549 is less frequent than parent $F355550\n",
      "$F355283 is less frequent than parent $F355287\n",
      "$F11431 is less frequent than parent $F11432\n",
      "500 : 370\n",
      "$F113753 is less frequent than parent $F113754\n",
      "1000 : 740\n",
      "1500 : 1103\n",
      "2000 : 1432\n",
      "2500 : 1773\n",
      "$F113618 is less frequent than parent $F113619\n",
      "3000 : 2115\n",
      "3500 : 2458\n",
      "$F28782 is less frequent than parent $F28783\n",
      "4000 : 2766\n",
      "4500 : 3099\n",
      "$F113672 is less frequent than parent $F113673\n",
      "5000 : 3412\n",
      "5500 : 3714\n",
      "6000 : 4021\n",
      "6500 : 4366\n",
      "7000 : 4666\n",
      "7500 : 4860\n",
      "8000 : 5182\n",
      "8500 : 5454\n",
      "9000 : 5705\n",
      "9500 : 5970\n",
      "$F192495 is less frequent than parent $F192496\n",
      "10000 : 6221\n",
      "$F289515 is less frequent than parent $F289516\n",
      "10500 : 6453\n",
      "11000 : 6635\n",
      "11500 : 6663\n",
      "12000 : 6663\n",
      "12500 : 6663\n",
      "13000 : 6663\n",
      "13500 : 6663\n",
      "14000 : 6663\n",
      "14500 : 6663\n",
      "15000 : 6663\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7224f47f046b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mfreq_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabstract_code_dict_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmost_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfreq_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0maccepted_functions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc2abs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmost_freq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmost_freq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Instead of reducing the compressed child frequency before, we do it with removing other tokens\n",
    "\n",
    "i = 0\n",
    "accepted_functions = []\n",
    "for key in abstract_code_keys:\n",
    "    if not i%500: print(i, \":\", len(accepted_functions))\n",
    "    i+=1\n",
    "    func = abstract_code_dict_copy[key]['compressed_name']\n",
    "    freq_dict[func] = abstract_code_dict_copy[key]['count']\n",
    "    most_freq = sorted(freq_dict, key = lambda x:freq_dict[x], reverse=True)\n",
    "    accepted_functions = list(set(func2abs) & set(most_freq[:vocab_size]))\n",
    "    \n",
    "    if func in most_freq[:vocab_size]:\n",
    "        count = abstract_code_dict_copy[key]['count']\n",
    "        children = abstract_code_dict_copy[key]['children']\n",
    "        accepted_functions.append(func)\n",
    "        tokens = key.split()\n",
    "        \n",
    "        # Should be recursive\n",
    "        if children:\n",
    "            for child in children:\n",
    "                if child in freq_dict:\n",
    "                    freq_dict[child] -= count\n",
    "                else:\n",
    "                    print(child, \"is less frequent than parent\", func)\n",
    "        else:\n",
    "            for token in tokens:\n",
    "                if not token.startswith(\"$id\") and token in freq_dict:\n",
    "                    freq_dict[token] -= count\n",
    "\n",
    "most_freq = sorted(freq_dict, key = lambda x:freq_dict[x], reverse=True)\n",
    "accepted_functions = list(set(func2abs) & set(most_freq[:vocab_size]))\n",
    "print(i, \":\", len(accepted_functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Adding one compressed token at a time to the dataset, reducing the frequency for all of it's tokens\n",
    "#### It's not entirely accurate because we cannot consider the identifier numbers\n",
    "#### But it's okay because we are taking an upper bound, so less compress tokens are fine, more are not\n",
    "\n",
    "i = 0\n",
    "accepted_functions = []\n",
    "for key in abstract_code_keys:\n",
    "    if not i%1000: print(i)\n",
    "    i+=1\n",
    "    most_freq = sorted(freq_dict, key = lambda x:freq_dict[x], reverse=True)\n",
    "    count = abstract_code_dict_copy[key]['count']\n",
    "    func = abstract_code_dict_copy[key]['compressed_name']\n",
    "    if func in most_freq[:vocab_size]:\n",
    "        accepted_functions.append(func)\n",
    "        tokens = key.split()\n",
    "        for token in tokens:\n",
    "            if not token.startswith(\"$id\") and token in freq_dict:\n",
    "                freq_dict[token] -= count\n",
    "print(i)\n",
    "len(accepted_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6663"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accepted_fucnctions = list(set([abstract_code_dict_copy[x]['compressed_name'] for x in abstract_code_dict_copy]))\n",
    "# ## Suggested functions in our estimation\n",
    "\n",
    "# accepted_functions = done_funcs\n",
    "len(accepted_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$F374504',\n",
       " '$F410006',\n",
       " '$F168134',\n",
       " '$F409064',\n",
       " '$F50242',\n",
       " '$F184471',\n",
       " '$F77718',\n",
       " '$F4569',\n",
       " '$F383217',\n",
       " '$F105243']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_functions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict[most_freq[vocab_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_compressed = []\n",
    "for token in accepted_functions:\n",
    "    to_be_compressed.append(func2abs[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6663, '< Page < LiveOutputInner > >')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_be_compressed), to_be_compressed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del abstract_code_keys\n",
    "abstract_code_keys = to_be_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6663"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstract_code_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### Testing Single compression\n",
    "i = 14\n",
    "data = copy.deepcopy(tree_data[i])\n",
    "uncompressed_code = tree2code(data, 0)[0]\n",
    "before_tokens = len(uncompressed_code.split())\n",
    "print(uncompressed_code, \"\\n\", before_tokens)\n",
    "\n",
    "(code, leaf_count, id_count, var_list) = compress(data)\n",
    "code = tree2code(data, 0)[0]\n",
    "after_tokens = len(code.split())\n",
    "print(code, \"\\n\", after_tokens)\n",
    "print(\"Compression Ratio: \", after_tokens/before_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(to_be_compressed, \"to_be_compressed_30k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_keys = getJsonData(\"to_be_compressed_30k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 ] : 0.8095238095238095\n",
      "[ 5000 ] : 0.8564257524562994\n",
      "[ 10000 ] : 0.856249825302981\n",
      "[ 15000 ] : 0.8523927947581553\n",
      "[ 20000 ] : 0.8569750104397331\n",
      "[ 25000 ] : 0.8424060075147535\n",
      "[ 29999 ] : 0.8120006470466895\n"
     ]
    }
   ],
   "source": [
    "compressed_freq_dict = {}\n",
    "compressed_codes = []\n",
    "total_tokens_before = 0\n",
    "total_tokens_after = 0\n",
    "for i in range(len(tree_data)):\n",
    "    try:\n",
    "        tree_copy = copy.deepcopy(tree_data[i])\n",
    "        code, _ = tree2code(tree_copy, 0)\n",
    "        total_tokens_before += len(code.split())\n",
    "        (code, leaf_count, id_count, var_list) = compress(tree_copy)\n",
    "        code, _ = tree2code(tree_copy, 0)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        code, _ = tree2code(tree_data[i], 0)\n",
    "    compressed_code = {\"code\": code}\n",
    "    tokens = code.split()\n",
    "    total_tokens_after += len(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in compressed_freq_dict:\n",
    "            compressed_freq_dict[token] = 0\n",
    "        compressed_freq_dict[token] += 1\n",
    "    compressed_codes.append(compressed_code)\n",
    "    if i%5000 == 0: print(\"[\", i, \"] :\", total_tokens_after/total_tokens_before) \n",
    "print(\"[\", i, \"] :\", total_tokens_after/total_tokens_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(compressed_codes, '../test_data/compressed_codes_train_3_30k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89140"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_most_freq = sorted(compressed_freq_dict, key = lambda x:compressed_freq_dict[x], reverse=True)\n",
    "len(compressed_most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6607"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_tokens_after_compression = list(set(compressed_most_freq[:vocab_size]) & set(accepted_functions))\n",
    "len(common_tokens_after_compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9915953774576017"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_tokens_after_compression)/len(accepted_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2217"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accepted_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[')',\n",
       " '(',\n",
       " ',',\n",
       " ';',\n",
       " '.',\n",
       " '{',\n",
       " '}',\n",
       " 'NUM00',\n",
       " '=',\n",
       " 'if',\n",
       " 'public',\n",
       " 'new',\n",
       " 'String',\n",
       " 'return',\n",
       " '<',\n",
       " '>',\n",
       " 'null',\n",
       " 'int',\n",
       " '==',\n",
       " '+',\n",
       " 'i',\n",
       " '[',\n",
       " ']',\n",
       " 'this',\n",
       " 'else',\n",
       " '!=',\n",
       " ':',\n",
       " '$F1',\n",
       " 'final',\n",
       " '-']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_most_freq[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov = list(set(accepted_functions) - set(compressed_most_freq[:vocab_size]))\n",
    "len(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ $id0 . ifModifiedSince = null ; } {'count': 22, 'compressed_name': '$F355291', 'num_params': 1, 'children': []}\n",
      "ServiceResponse < Void > {'count': 584, 'compressed_name': '$F355581', 'num_params': 0, 'children': ['$F19311']}\n",
      "long $id0 = $id1 . currentTimeMillis ( ) {'count': 67, 'compressed_name': '$F11431', 'num_params': 2, 'children': []}\n",
      "{ $id0 . lastModified = null ; } {'count': 47, 'compressed_name': '$F356833', 'num_params': 1, 'children': []}\n",
      "$id0 != null ? $id0 . skip ( ) : null {'count': 17, 'compressed_name': '$F361252', 'num_params': 1, 'children': []}\n",
      "ServiceResponse < OperationStatus > {'count': 190, 'compressed_name': '$F361296', 'num_params': 0, 'children': ['$F361287']}\n",
      "boolean $id0 = $id1 . $id0 ( ) {'count': 20, 'compressed_name': '$F92224', 'num_params': 2, 'children': []}\n",
      "{ $id0 . ifUnmodifiedSince = null ; } {'count': 22, 'compressed_name': '$F355294', 'num_params': 1, 'children': []}\n",
      "{ $id0 . ocpDate = null ; } {'count': 59, 'compressed_name': '$F355283', 'num_params': 1, 'children': []}\n",
      "$id0 . body ( ) . nextPageLink ( ) {'count': 166, 'compressed_name': '$F355549', 'num_params': 1, 'children': ['$F355548']}\n",
      "ServiceResponse < OperationStatusResponseInner > {'count': 64, 'compressed_name': '$F361644', 'num_params': 0, 'children': ['$F361635']}\n",
      "$id0 != null ? $id0 . name ( ) : null {'count': 27, 'compressed_name': '$F393135', 'num_params': 1, 'children': []}\n",
      "CacheMgmtInterceptor . class {'count': 18, 'compressed_name': '$F115793', 'num_params': 0, 'children': []}\n",
      "ServiceResponse < UUID > {'count': 105, 'compressed_name': '$F396397', 'num_params': 0, 'children': ['$F16971']}\n",
      "$id0 . body ( ) . items ( ) {'count': 14, 'compressed_name': '$F361728', 'num_params': 1, 'children': ['$F361727']}\n",
      "$id0 != null ? $id0 . take ( ) : null {'count': 19, 'compressed_name': '$F361255', 'num_params': 1, 'children': []}\n"
     ]
    }
   ],
   "source": [
    "for o in oov:\n",
    "    a = abstract_code_dict[func2abs[o]]\n",
    "    print(func2abs[o], a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'$F406149' in compressed_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "common_tokens_after_compression[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab 10k, compression ratio: 0.8567161502728318\n",
    "# vocab 30k, compression ratio: 0.8987381335587129"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
