{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../CodeSearchNet/big_csn_data/CodeSearchNet_Java_Search_Preliminary.pkl\"\n",
    "infile = open(filename,'rb')\n",
    "new_dict = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1569889"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private static String interpretFacet(final Facet facet) {\n",
      "        if (facet == null || facet.isNoop()) {\n",
      "            return \"\";\n",
      "        }\n",
      "        if (facet instanceof ImperativeFacet) {\n",
      "            ImperativeFacet imperativeFacet = (ImperativeFacet) facet;\n",
      "            return imperativeFacet.getMethods().get(0).getName();\n",
      "        } \n",
      "        final String name = facet.getClass().getSimpleName();\n",
      "        if (ignore(name)) {\n",
      "            return \"\";\n",
      "        } \n",
      "        final String abbr = StringExtensions.toAbbreviation(name);\n",
      "        return abbr.length()>0 ? abbr : name;\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "i = -1#+(100000)*15\n",
    "print(new_dict[i]['function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dict[i]['function_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonDataLineByLine(JsonFile):\n",
    "    data = []\n",
    "    i = 0\n",
    "    with open(JsonFile) as f:\n",
    "        for line in f:\n",
    "            i += 1\n",
    "            line = line.strip()\n",
    "            if line[0] == '[':\n",
    "                line = line[1:]\n",
    "            elif line[-1] == ']':\n",
    "                line = line[:-1]\n",
    "            if line[-1] == ',':\n",
    "                line = line[:-1]\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "                if i%10000 == 0: print(i, \"success\")\n",
    "            except:\n",
    "                data.append('''{\"classBodyDeclaration\": \"\"}''')\n",
    "                print(i, \"failure\")\n",
    "                print(line)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonDataSafe(JsonFile):\n",
    "    try:\n",
    "        return getJsonData(JsonFile)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Loading JSON failed. Attempting safe method.\")\n",
    "        return getJsonDataLineByLine(JsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dict(data, name):\n",
    "    with open(name, 'w', encoding=\"utf8\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travarse(tree):\n",
    "    if 'type' in tree:\n",
    "        print(tree['text'], end=\" \")\n",
    "        if tree['text'] in [';', '{', '}']:\n",
    "            print()\n",
    "        return\n",
    "    else:\n",
    "        root = list(tree.keys())[0]\n",
    "        children = tree[root]\n",
    "        for child in children:\n",
    "            travarse(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree2code(tree, indentation):\n",
    "    if 'type' in tree:\n",
    "        code = tree['text'] + ' '\n",
    "        if tree['text'] in [';', '{', '}']:\n",
    "            code += '\\n'\n",
    "            if tree['text'] == '{':\n",
    "                indentation += 1\n",
    "            elif tree['text'] == '}':\n",
    "                indentation -= 1\n",
    "            code += '\\t'*indentation\n",
    "        return code, indentation\n",
    "    else:\n",
    "        root = list(tree.keys())[0]\n",
    "        children = tree[root]\n",
    "        code = \"\"\n",
    "        for child in children:\n",
    "            t, indentation = tree2code(child, indentation)\n",
    "            code += t\n",
    "        return code, indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printCode(tree):\n",
    "    code, _ = tree2code(tree, 0)\n",
    "    print(code)\n",
    "    print(\"Count:\", len(code.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csn_big_10_compressed.json    csn_big_2_compressed.json\r\n",
      "csn_big_10.json               csn_big_2.json\r\n",
      "csn_big_11u_compressed.json   csn_big_3_compressed.json\r\n",
      "csn_big_11u.json              csn_big_3.json\r\n",
      "csn_big_12_compressed.json    csn_big_4u_compressed.json\r\n",
      "csn_big_12.json               csn_big_4u.json\r\n",
      "csn_big_13uu_compressed.json  csn_big_5_compressed.json\r\n",
      "csn_big_13uu.json             csn_big_5.json\r\n",
      "csn_big_14_compressed.json    csn_big_6_compressed.json\r\n",
      "csn_big_14.json               csn_big_6.json\r\n",
      "csn_big_15_compressed.json    csn_big_7u_compressed.json\r\n",
      "csn_big_15.json               csn_big_7u.json\r\n",
      "csn_big_16_compressed.json    csn_big_8_compressed.json\r\n",
      "csn_big_16_d.json             csn_big_8.json\r\n",
      "csn_big_1u_compressed.json    csn_big_9u_compressed.json\r\n",
      "csn_big_1u.json               csn_big_9u.json\r\n"
     ]
    }
   ],
   "source": [
    "ls ../csn_big_only_trees/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompressed_data = getJsonData('../csn_big_only_trees/csn_big_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_data = getJsonData('../csn_big_only_trees/csn_big_1_compressed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19709767475553153\n"
     ]
    }
   ],
   "source": [
    "bef_comp = 0\n",
    "aft_comp = 0\n",
    "for i in range(len(compressed_data)):\n",
    "    code, _ = tree2code(uncompressed_data[i], 0)\n",
    "    num_tokens = len(code.split())\n",
    "    compressed_tokens = len(compressed_data[i]['code'].split())\n",
    "    bef_comp += num_tokens\n",
    "    aft_comp += compressed_tokens\n",
    "    if not compressed_tokens:\n",
    "        aft_comp += num_tokens\n",
    "\n",
    "print(1-aft_comp/bef_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private List < ConfigurationPlaceholderResolver > loadAndOrderPlaceholderResolvers ( ) { \n",
      "\tfinal List < ConfigurationPlaceholderResolver > configurationPlaceholderResolvers = new ArrayList < ConfigurationPlaceholderResolver > ( serviceLoaderInstance . get ( ) . all ( ConfigurationPlaceholderResolver . class ) ) ; \n",
      "\tCollections . sort ( configurationPlaceholderResolvers , new Comparator < ConfigurationPlaceholderResolver > ( ) { \n",
      "\t\tpublic int compare ( ConfigurationPlaceholderResolver firstResolver , ConfigurationPlaceholderResolver secondResolver ) { \n",
      "\t\t\tInteger a = firstResolver . precedence ( ) ; \n",
      "\t\t\tInteger b = secondResolver . precedence ( ) ; \n",
      "\t\t\treturn b . compareTo ( a ) ; \n",
      "\t\t\t} \n",
      "\t\t} \n",
      "\t) ; \n",
      "\treturn configurationPlaceholderResolvers ; \n",
      "\t} \n",
      "\n",
      "95\n",
      "================================\n",
      "private List < ConfigurationPlaceholderResolver > loadAndOrderPlaceholderResolvers $F2 { \n",
      "\tfinal List < ConfigurationPlaceholderResolver > configurationPlaceholderResolvers = new ArrayList < ConfigurationPlaceholderResolver > ( $F144 ( serviceLoaderInstance ) . all ( ConfigurationPlaceholderResolver . class ) ) ; \n",
      "\tCollections . sort ( configurationPlaceholderResolvers , new Comparator < ConfigurationPlaceholderResolver > $F2 { \n",
      "\t\tpublic int compare ( ConfigurationPlaceholderResolver firstResolver , ConfigurationPlaceholderResolver secondResolver ) { \n",
      "\t\t\tInteger a = firstResolver . precedence ( ) ; \n",
      "\t\t\tInteger b = secondResolver . precedence ( ) ; \n",
      "\t\t\t$F43821 ( b , a ) } \n",
      "\t\t} \n",
      "\t) ; \n",
      "\treturn configurationPlaceholderResolvers ; \n",
      "\t} \n",
      "\n",
      "90\n",
      "Compression Ratio: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "code, _ = tree2code(uncompressed_data[i], 0)\n",
    "num_tokens = len(code.split())\n",
    "print(code)\n",
    "print(num_tokens)\n",
    "print(\"================================\")\n",
    "print(compressed_data[i]['code'])\n",
    "compressed_tokens = len(compressed_data[i]['code'].split())\n",
    "print(compressed_tokens)\n",
    "print(\"Compression Ratio:\", compressed_tokens/num_tokens)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2104572106016639\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2104572106016639"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
