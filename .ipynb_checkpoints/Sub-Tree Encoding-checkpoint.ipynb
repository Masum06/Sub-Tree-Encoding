{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonDataLineByLine(JsonFile):\n",
    "    data = []\n",
    "    i = 0\n",
    "    with open(JsonFile) as f:\n",
    "        for line in f:\n",
    "            i += 1\n",
    "            line = line.strip()\n",
    "            if line[0] == '[':\n",
    "                line = line[1:]\n",
    "            elif line[-1] == ']':\n",
    "                line = line[:-1]\n",
    "            if line[-1] == ',':\n",
    "                line = line[:-1]\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "                if i%10000 == 0: print(i, \"success\")\n",
    "            except:\n",
    "                data.append('''{\"classBodyDeclaration\": \"\"}''')\n",
    "                print(i, \"failure\")\n",
    "                print(line)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonDataSafe(JsonFile):\n",
    "    try:\n",
    "        return getJsonData(JsonFile)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Loading JSON failed. Attempting safe method.\")\n",
    "        return getJsonDataLineByLine(JsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dict(data, name):\n",
    "    with open(name, 'w', encoding=\"utf8\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travarse(tree):\n",
    "    if 'type' in tree:\n",
    "        print(tree['text'], end=\" \")\n",
    "        if tree['text'] in [';', '{', '}']:\n",
    "            print()\n",
    "        return\n",
    "    else:\n",
    "        root = list(tree.keys())[0]\n",
    "        children = tree[root]\n",
    "        for child in children:\n",
    "            travarse(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree2code(tree, indentation):\n",
    "    if 'type' in tree:\n",
    "        code = tree['text'] + ' '\n",
    "        if tree['text'] in [';', '{', '}']:\n",
    "            code += '\\n'\n",
    "            if tree['text'] == '{':\n",
    "                indentation += 1\n",
    "            elif tree['text'] == '}':\n",
    "                indentation -= 1\n",
    "            code += '\\t'*indentation\n",
    "        return code, indentation\n",
    "    else:\n",
    "        root = list(tree.keys())[0]\n",
    "        children = tree[root]\n",
    "        code = \"\"\n",
    "        for child in children:\n",
    "            t, indentation = tree2code(child, indentation)\n",
    "            code += t\n",
    "        return code, indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printCode(tree):\n",
    "    code, _ = tree2code(tree, 0)\n",
    "    print(code)\n",
    "    print(\"Count:\", len(code.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def get_compressed_func():\n",
    "    global compression_number\n",
    "    compression_number += 1\n",
    "    return \"$F\"+str(compression_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict(tree):\n",
    "    var_list = []\n",
    "    global abstract_code_dict\n",
    "    global num_to_compress\n",
    "    global function2abstract\n",
    "    \n",
    "    if 'text' in tree:\n",
    "        code = tree[\"text\"] + \" \"\n",
    "        #print(\"**:\\t\",code, 1)\n",
    "        return (code, 1, 0, [], None)\n",
    "    else:\n",
    "        parent = list(tree.keys())[0]\n",
    "        children = tree[parent]\n",
    "        if len(children) == 0:\n",
    "            return (\"\", 0, 0, [], None)\n",
    "        \n",
    "        code = \"\"\n",
    "        compressed_func = None\n",
    "        leaf_count = 0\n",
    "        id_count = 0\n",
    "        children_list = []\n",
    "        #leaf_list = []\n",
    "        \n",
    "        '''and not (len(children) == 2 and 'text' in children[1] and children[1]['text'] == ';')\\\n",
    "        and not (len(children) == 3 and 'text' in children[0] and 'text' in children[2] and \\\n",
    "                 ((children[0]['text'] == '(' and children[2]['text'] == ')') or \n",
    "                  (children[0]['text'] == '{' and children[2]['text'] == '}') or\n",
    "                  (children[0]['text'] == '[' and children[2]['text'] == ']')))'''\n",
    "        \n",
    "        if len(children) > 1:\n",
    "            for child in children:\n",
    "                (c, n, i, vl, f) = build_dict(child)\n",
    "                code += c\n",
    "                leaf_count += n\n",
    "                id_count += i\n",
    "                var_list += [v for v in vl if v not in var_list]\n",
    "                if f: children_list.append(f)\n",
    "                #else: leaf_list += code.split()\n",
    "                \n",
    "            if (var_list and leaf_count - len(var_list) >= 4) or (not var_list and leaf_count > 1) :\n",
    "                abstract_code = code.split()\n",
    "                for i in range(len(abstract_code)):\n",
    "                    if abstract_code[i] in var_list:\n",
    "                        abstract_code[i] = \"$id{}\".format(var_list.index(abstract_code[i]))\n",
    "                abstract_code = ' '.join(abstract_code)\n",
    "                \n",
    "                if abstract_code not in abstract_code_dict:\n",
    "                    compressed_func = get_compressed_func()\n",
    "                    abstract_code_dict[abstract_code] = {\n",
    "                        'count': 0, \n",
    "                        'compressed_name': compressed_func,\n",
    "                        'num_params': len(var_list),\n",
    "                        'children': children_list,\n",
    "                        #'leaves': leaf_list\n",
    "                    }\n",
    "                    function2abstract[compressed_func] = abstract_code\n",
    "                else:\n",
    "                    compressed_func = abstract_code_dict[abstract_code]['compressed_name']\n",
    "                \n",
    "                abstract_code_dict[abstract_code]['count'] += 1\n",
    "#                 children_list.insert(0, compressed_func)\n",
    "                \n",
    "            return (code, leaf_count, id_count, var_list, compressed_func)\n",
    "        \n",
    "        if parent == \"literal\":\n",
    "            child = children[0]\n",
    "            child_text = child[\"text\"]\n",
    "            try:\n",
    "                if child_text in ['null', 'true', 'false']:\n",
    "                    pass\n",
    "                elif type(ast.literal_eval(child_text)) == type(\"STRING\"):\n",
    "                    children[0][\"text\"] = \"STRING00\"\n",
    "                elif type(ast.literal_eval(child_text)) == type(1):\n",
    "                    children[0][\"text\"] = \"INT00\"\n",
    "                elif type(ast.literal_eval(child_text)) == type(1.1):\n",
    "                    children[0][\"text\"] = \"FLOAT00\"\n",
    "            except:\n",
    "                children[0][\"text\"] = \"NUM00\"\n",
    "        elif parent == \"primary\" and 'type' in children[0]:\n",
    "            id_count += 1\n",
    "            text = children[0][\"text\"]\n",
    "            if text not in var_list:\n",
    "                var_list.append(text)\n",
    "        elif parent == \"variableDeclaratorId\" and 'type' in children[0]:\n",
    "            id_count += 1\n",
    "            text = children[0][\"text\"]\n",
    "            if text not in var_list:\n",
    "                var_list.append(text)\n",
    "\n",
    "        (code, leaf_count, i, vl, fns) = build_dict(children[0])\n",
    "        id_count += i\n",
    "        var_list += [v for v in vl if v not in var_list]\n",
    "        \n",
    "        return (code, leaf_count, id_count, var_list, fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in abstract_code_keys:\n",
    "#     if key+\" ;\" in abstract_code_keys:\n",
    "#         del abstract_code_dict[key]+\" ;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getJsonData('../CodeSearchNet/train_test_valid_uncompressed/java_train_0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tree2code(data[0], 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_dict = {}\n",
    "compression_number = 0\n",
    "function2abstract = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_dict(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abstract_code_keys = sorted(abstract_code_dict, key = lambda x:abstract_code_dict[x]['count'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"data[0]\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Num_to_compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Code from Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "paths = glob.glob('../CodeSearchNet/train_test_valid_uncompressed/*_train_*.json')\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## build freq_dict\n",
    "train_codes = []\n",
    "freq_dict = {}\n",
    "for path in paths:\n",
    "    print(path)\n",
    "    data = getJsonData(path)\n",
    "    for i in range(len(data)):\n",
    "        if i%5000 == 0: print(\"[\", i, \"]\")\n",
    "        code, _ = tree2code(data[i], 0)\n",
    "        tokens = code.split()\n",
    "        train_codes.append({\"code\": code, \"count\":len(tokens)})\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token not in freq_dict: freq_dict[token] = 0\n",
    "            freq_dict[token] += 1\n",
    "\n",
    "dump_dict(train_codes, \"../CodeSearchNet/training_codes_uncompressed.json\")\n",
    "dump_dict(freq_dict, \"../CodeSearchNet/training_freq_dict.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = getJsonData(\"../CodeSearchNet/training_freq_dict.json\")\n",
    "abstract_code_dict = getJsonData(\"../CodeSearchNet/abstract_code_dict_500k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_keys = sorted(abstract_code_dict, key = lambda x:abstract_code_dict[x]['count'], reverse=True)\n",
    "most_frequent_list = sorted(freq_dict, key = lambda x:freq_dict[x], reverse=True)\n",
    "len(abstract_code_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize vocab_size\n",
    "vocab_size = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abstract_code_dict[abstract_code_keys[vocab_size]]['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict[most_frequent_list[vocab_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all just ; added tokens\n",
    "# When adding a parent to the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add func_names from abstract_code_dict, set count: 0\n",
    "import copy\n",
    "\n",
    "freq_dict_compressed = {} #copy.deepcopy(freq_dict)\n",
    "\n",
    "for x in most_frequent_list[vocab_size-4]:\n",
    "    freq_dict_compressed[x] = freq_dict[x]\n",
    "\n",
    "# for i in range(len(abstract_code_dict)):\n",
    "#     func = '$F'+str(i)\n",
    "#     freq_dict_compressed[func] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "num_to_compress = 0\n",
    "for i in range(len(abstract_code_keys)):\n",
    "    if i%10 == 0: print('[[',i,']]')\n",
    "    func_name = abstract_code_dict[abstract_code_keys[i]]['compressed_name']\n",
    "    code = abstract_code_keys[i]\n",
    "    count = abstract_code_dict[abstract_code_keys[i]]['count']\n",
    "    num_params = abstract_code_dict[abstract_code_keys[i]]['num_params']\n",
    "    most_frequent_list = sorted(freq_dict_compressed, key = lambda x:freq_dict_compressed[x], reverse=True)\n",
    "    \n",
    "    if count >= freq_dict_compressed[most_frequent_list[vocab_size-4]]: # KEEPING PLACE FOR 4 SPECIAL TOKENS00\n",
    "        token_list = code.split()\n",
    "        for token in token_list:\n",
    "            if not token.startswith('$id') and token not in ['STRING00', 'INT00','FLOAT00', 'NUM00']:\n",
    "                freq_dict_compressed[token] -= count\n",
    "        freq_dict_compressed[func_name] = count\n",
    "        if num_params > 0:\n",
    "            freq_dict_compressed[\"(\"] += 1\n",
    "            freq_dict_compressed[\")\"] += 1\n",
    "    else:\n",
    "        num_to_compress = i\n",
    "        print(\"Number to Compress:\",i)\n",
    "        break\n",
    "most_frequent_list = sorted(freq_dict, key = lambda x:freq_dict[x], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "most_frequent_list = sorted(freq_dict_compressed, key = lambda x:freq_dict_compressed[x], reverse=True)\n",
    "end = datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'$id0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(abstract_code_dict, 'abstract_code_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_dict = getJsonData('../CodeSearchNet/abstract_code_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_keys = sorted(abstract_code_dict, key = lambda x:abstract_code_dict[x]['count'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abstract_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(abstract_code_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freqs = []\n",
    "for x in abstract_code_keys[:100]:\n",
    "    freq = abstract_code_dict[x]['count']\n",
    "    freqs.append(freq)\n",
    "    print(freq, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freqs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_frac = 0\n",
    "frac = 0.2\n",
    "sum_100 = sum(freqs)\n",
    "for i in range(len(freqs)):\n",
    "    sum_frac += freqs[i]\n",
    "    if sum_frac >= frac*sum_100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freqs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5M data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_dict = {}\n",
    "compression_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "data_start_number = 1\n",
    "data_end_number = 16\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "for n in range(data_start_number, data_end_number+1):\n",
    "    print(\"=====[\",n,\"]=====\")\n",
    "    try:\n",
    "        all_data = getJsonDataSafe(\"../csn_big_only_trees/csn_big_{}.json\".format(n))\n",
    "        for i in range(len(all_data)):\n",
    "            if i%10000 == 0: print(\"[\", i, \"]\") \n",
    "            tree_copy = copy.deepcopy(all_data[i])\n",
    "            (code, leaf_count, id_count, var_list) = build_n_compress(tree_copy, True)\n",
    "    except:\n",
    "        print(\"Data csn_big_{}.json is corrupted.\".format(n))\n",
    "        \n",
    "    for key in list(abstract_code_dict):\n",
    "        if abstract_code_dict[key]['count'] < 2:\n",
    "            del abstract_code_dict[key]\n",
    "    # Print Time\n",
    "    end = datetime.datetime.now()\n",
    "    print(end-start)\n",
    "abstract_code_keys = sorted(abstract_code_dict, key = lambda x:abstract_code_dict[x]['count'], reverse=True)\n",
    "end = datetime.datetime.now()\n",
    "print(\"Dictionary building complete in - \",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dictionary Training data: 500k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "paths = glob.glob('../CodeSearchNet/train_test_valid_uncompressed/*_train_*.json')\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_dict = {}\n",
    "compression_number = 0\n",
    "function2abstract = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "for path in paths:\n",
    "    print(\"=====[\",path,\"]=====\")\n",
    "#     try:\n",
    "    all_data = getJsonData(path)\n",
    "    for i in range(len(all_data)):\n",
    "        if i%10000 == 0:\n",
    "            now = datetime.datetime.now()\n",
    "            print(now - start,\": [\", i, \"]\") \n",
    "        tree_copy = copy.deepcopy(all_data[i])\n",
    "        (code, leaf_count, id_count, var_list, _) = build_dict(tree_copy)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(\"File {} is corrupted. Cannot create dictionary.\".format(path))\n",
    "        \n",
    "    for key in list(abstract_code_dict):\n",
    "        if abstract_code_dict[key]['count'] < 2:\n",
    "            del abstract_code_dict[key]\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    print(end-start)\n",
    "abstract_code_keys = sorted(abstract_code_dict, key = lambda x:abstract_code_dict[x]['count'], reverse=True)\n",
    "end = datetime.datetime.now()\n",
    "print(\"Dictionary building complete in - \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(abstract_code_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(abstract_code_dict, '../CodeSearchNet/abstract_code_dict_500k_w_child.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save dictionary in zip file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f abstract_code_dict_1.5m.zip\n",
    "!zip abstract_code_dict_1.5m.zip abstract_code_dict_1.5m.json\n",
    "!rm -f abstract_code_dict_1.5m.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dictionary from zip file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip abstract_code_dict_1.5m.zip\n",
    "abstract_code_dict = getJsonData('abstract_code_dict_1.5m.json')\n",
    "!rm -f abstract_code_dict_1.5m.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_code_keys = sorted(abstract_code_dict, key = lambda x:abstract_code_dict[x]['count'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compress.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "!echo $n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip abstract_code_dict_1.5m.zip\n",
    "for n in range(data_start_number, data_end_number+1):\n",
    "    !python compress.py $n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing Train-Test-Valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls ../csn_big_only_trees/*compressed.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = [\n",
    "    '../csn_big_only_trees/csn_big_10_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_11u_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_12_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_13uu_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_14_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_15_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_16_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_1u_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_2_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_3_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_4u_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_5_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_6_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_7u_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_8_compressed.json',\n",
    "    '../csn_big_only_trees/csn_big_9u_compressed.json',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for file in files:\n",
    "    data = getJsonData(file)\n",
    "    all_data += data\n",
    "\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(all_data, '../search_data_100k_compressed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip ../search_data_100k_compressed.zip ../search_data_100k_compressed.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
